{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390dad44",
   "metadata": {},
   "source": [
    "Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f647e8c",
   "metadata": {},
   "source": [
    "1.The key factor that distinguishes ideas that can be tested statistically from those that cannot is measurability. A testable idea must involve variables that can be observed, quantified, and analyzed by using data. It should lead to clear predictions that can be evaluated through experimentation or data analysis. in otehr words, ideas that are vague, subjective, or not grounded in measurable outcomes cannot be tested statistically.\n",
    "\n",
    "2.A good null hypothesis must be specific, falsifiable, neutral and testable. Firstly, a good null hypothesis must be precise and clearly defined. Secondly, a good null hypothesis should be structured in a disproven way. After it is assumed, we need to look for evidence to contradict it. Thirdly, a good null hypothesis must be possible to collect data to support or refute itself. Last but not least, a good null hypothsis shouold not favor any particular outcome, but it suppose to generally represent the absence of an effect or a relationship. Generally speaking a good null hypothesis must have specificity,falsifiability, neutrality and testability. \n",
    "\n",
    "3.The difference between a null hypothesis and an alternative hypothesis is that the null hypothesis is what we assume to be true unless we have strong evidence against it.\n",
    "However, the alternative hypothesis represents the opposite of the null hypothesis.This is what we consider true if the null hypothesis is rejected based on statistical evidence.\n",
    "\n",
    "To be more precise, the null hypothesis represents the default assumption or status quo in a statistical test. It typically states that there is no effect, no difference, or no relationship between the variables being studied. The goal of hypothesis testing is to determine whether there is enough evidence to reject the null hypothesis.\n",
    "By contradiction, It suggests that there is an effect, a difference, or a relationship between the variables. If sufficient evidence is found to reject the null hypothesis, the alternative hypothesis is supported.\n",
    "\n",
    "https://chatgpt.com/share/670f330f-1698-8007-8d00-40f0c7c5a851"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd022362",
   "metadata": {},
   "source": [
    "Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb6ba2",
   "metadata": {},
   "source": [
    " The statement means that while we calculate a result from our sample, we are ultimately trying to understand the true situation for the entire population based on what we find in a smaller group (sample). And the result of our test gives us information about the population, not just the sample. So, while we might calculate an average effect from our sample, what we really want to know is the true average effect on everyone (the population). The results we get from our sample help us make educated guesses about the overall effects on the population, but they are only estimates. In other words, when we conduct a hypothesis test, we are not just interested in the data we collected (the sample), but in what it tells us about the entire group we're studying (the population).\n",
    "\n",
    "Defining the technical statistical terminology:\n",
    "\n",
    "Population: This refers to the entire group we want to understand or make conclusions about. For example, if we are studying a new vaccine, the population could be all the people who would potentially receive it.\n",
    "\n",
    "Sample: This is a smaller group taken from the population that we actually test or observe. It is like taking a snapshot of the larger group to make estimates about it.\n",
    "\n",
    "Population Parameter (M): This is a specific value that describes a characteristic of the population, like the average effect of the vaccine on all potential users. It is a true value we often want to know but can’t measure directly.\n",
    "\n",
    "Sample Statistic (x): This is a value calculated from the sample, like the average effect observed in the people we tested. This value is used to estimate the population parameter.\n",
    "\n",
    "Distinctions between xi, x, M, and Mo:\n",
    "\n",
    "xi: Represents individual data points in the sample. For example, if we test five people, their individual responses (effects of the vaccine) would be x1, x2, x3, x4, and x5.\n",
    "\n",
    "x: The average of these individual responses (xi’s) in our sample. It gives us a summary of what we found in the sample.\n",
    "\n",
    "M (Population Mean): The average value we believe is true for the entire population. It’s what we are trying to estimate based on our sample.\n",
    "\n",
    "Mo (Hypothesized Population Mean): This is a specific value we assume is true for the population before we do our testing. We often compare our sample findings against this value to see if our results are statistically significant.\n",
    "\n",
    "\n",
    "https://chatgpt.com/share/670f33cf-5c8c-8007-9cb8-71797c6afd95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b697aef8",
   "metadata": {},
   "source": [
    "Q3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075eaeeb",
   "metadata": {},
   "source": [
    "\"imagine a world where the null hypothesis is true\" when calculating a p-value, it means we start by assuming that there is no effect, no difference, or no relationship between the variables we are testing. Essentially, we are pretending that what we are trying to disprove is actually correct.\n",
    "\n",
    "The p-value helps us determine how likely it is to get the results we observed if the null hypothesis were true. So, if the p-value is very small, it means that the chance of getting our observed data under the assumption that the null hypothesis is true is very unlikely. In that case, we have evidence to reject the null hypothesis and support the idea that be represented by the alternative hypothesis is going on.\n",
    "\n",
    "Defining the technical statistical terminology:\n",
    "\n",
    "Null Hypothesis (H₀): the starting assumption in a hypothesis test, which states that there is no effect, no difference, or no relationship between the variables being tested. \n",
    "\n",
    "p-value: a number that helps us measure the strength of the evidence against the null hypothesis. Specifically, it tells us the probability of observing the data if the null hypothesis is true. A small p-value (usually less than 0.05) suggests that the observed results are unlikely under the null hypothesis, and thus provides evidence against it.\n",
    "\n",
    "Alternative Hypothesis (H₁): This is the opposite of the null hypothesis. It states that there is an effect, a difference, or a relationship between the variables. If we find enough evidence to reject the null hypothesis, we support the alternative hypothesis.\n",
    "\n",
    "Random Chance: This refers to the natural variation that can occur when you collect data. Even if there's no real effect (as the null hypothesis assumes), we might still see some differences in our sample due to random fluctuations. The p-value helps us decide if these differences are big enough to suggest something more than just random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e029294",
   "metadata": {},
   "source": [
    "Q4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7428e479",
   "metadata": {},
   "source": [
    "  A smaller p-value makes the null hypothesis look more ridiculous because it shows that the results we observed are very unlikely to happen by random chance if the null hypothesis were actually true.\n",
    "  \n",
    "  I will give an example to describe it exactly.\n",
    "  Suppose the null hypothesis is that a new vaccine has no effect. We run a test and find a tiny p-value, for example 0.002. This means that if the vaccine really had no effect, the chances of seeing the improvements we observed or something even more extreme in our patients are only 0.2%.\n",
    "\n",
    "In this case, the null hypothesis starts to look absurd， because it is saying the vaccine does not work, but we got these great results anyway. Thus, we might reject the null hypothesis and conclude the drug likely has an effect, which contradict the true meaning of null hypothesis.\n",
    "\n",
    "Defining the technical statistical terminology:\n",
    "\n",
    "Null Hypothesis (H₀): the starting assumption in a hypothesis test, which states that there is no effect, no difference, or no relationship between the variables being tested. \n",
    "\n",
    "p-value: a number that helps us measure the strength of the evidence against the null hypothesis. Specifically, it tells us the probability of observing the data if the null hypothesis is true. A small p-value (usually less than 0.05) suggests that the observed results are unlikely under the null hypothesis, and thus provides evidence against it.\n",
    "\n",
    "Random Chance: This refers to the natural variation that can occur when you collect data. Even if there's no real effect (as the null hypothesis assumes), we might still see some differences in our sample due to random fluctuations. The p-value helps us decide if these differences are big enough to suggest something more than just random chance.\n",
    "\n",
    "Rejecting the Null Hypothesis: If the p-value is small enough, we conclude that it's unlikely the data happened by chance alone, and we reject the null hypothesis. This means we believe there is enough evidence to support the idea that something is going on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef0eca",
   "metadata": {},
   "source": [
    "Q5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02910fdc",
   "metadata": {},
   "source": [
    "To simulate a p-value using a \"50/50 coin-flipping\" model for the head tilt assumption in kissing couples, we can assume each couple has a 50% chance of tilting their head to the right (null hypothesis: no preference for left or right).\n",
    "\n",
    "Steps to simulate the p-value:\n",
    "1.Null Hypothesis (H₀): The head tilt is random, so the probability of tilting either to the left or right is 50%.\n",
    "Observed data: In the study, 80 out of 124 couples tilted their heads to the right.\n",
    "2.Simulate: We simulate multiple trials, where for each trial, we \"flip a coin\" 124 times (representing the 124 couples) and count how many heads (right tilts) we get, assuming a 50% probability.\n",
    "3.Calculate p-value: The p-value will be the proportion of simulated trials where 80 or more heads tilt right, which represents the probability of observing a head tilt percentage of 64.5% or more by random chance if the null hypothesis were true.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e98423",
   "metadata": {},
   "source": [
    "Q6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ec120",
   "metadata": {},
   "source": [
    "A smaller p-value does not definitively prove that the null hypothesis is false.\n",
    "\n",
    "Firstly, a p-value is a measure of the strength of evidence against the null hypothesis (H₀). It tells us how likely we would observe our data, or something more extreme, if the null hypothesis were true. A p-value can indicate whether there is strong evidence against the null hypothesis, but it does not provide proof. Statistical tests deal with probabilities, not certainties. Even a very small p-value  suggests that the null hypothesis is unlikely, but it does not prove that it is false in an absolute sense. There could still be other explanations or factors at play.\n",
    "\n",
    "Moreover, there is no specific p-value threshold that can be universally set to definitively prove either the null hypothesis or its alternative. Traditional thresholds are often used to guide decision-making, but they do not offer definitive proof.\n",
    "\n",
    "In terms of Fido's Innocence or Guilt, if we set up a hypothesis test where the null hypothesis is that Fido is innocent, a small p-value would suggest strong evidence against this hypothesis. However, it would not prove that Fido is guilty; it would only suggest that the evidence against his innocence is strong.\n",
    "\n",
    "TO sum up, A smaller p-value indicates stronger evidence against the null hypothesis but does not prove it is false. Similarly, a larger p-value suggests insufficient evidence to reject the null hypothesis, but it does not prove that it is true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3ee3f",
   "metadata": {},
   "source": [
    "Q7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa0d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example patient data creation for demonstration purposes\n",
    "# Replace this with your actual patient data DataFrame\n",
    "np.random.seed(1)\n",
    "num_patients = 10\n",
    "patient_data = pd.DataFrame({\n",
    "    'HealthScoreChange': np.random.randn(num_patients)  # Random normal values simulating health score changes\n",
    "})\n",
    "\n",
    "# Display the observed health score changes and whether they are greater than zero\n",
    "print(pd.DataFrame({'HealthScoreChange': patient_data['HealthScoreChange'],\n",
    "                    '> 0 ?': patient_data['HealthScoreChange'] > 0}))\n",
    "\n",
    "# Create a random difference sign for simulation\n",
    "random_difference_sign = np.random.choice([-1, 1], size=len(patient_data))\n",
    "simulated_health_scores = random_difference_sign * patient_data['HealthScoreChange'].abs()\n",
    "\n",
    "# Display the simulated health score changes\n",
    "print(pd.DataFrame({'HealthScoreChange': simulated_health_scores,\n",
    "                    '> 0 ?': (simulated_health_scores) > 0}))\n",
    "\n",
    "# Set up for the hypothesis testing\n",
    "np.random.seed(1)  # Make the simulation reproducible\n",
    "number_of_simulations = 10000  # Number of simulations\n",
    "n_size = len(patient_data)  # Number of patients\n",
    "IncreaseProportionSimulations_underH0random = np.zeros(number_of_simulations)\n",
    "\n",
    "# Generate random improvement proportions assuming H0 (null hypothesis)\n",
    "for i in range(number_of_simulations):\n",
    "    random_improvement = np.random.choice([0, 1], size=len(patient_data), replace=True)\n",
    "    IncreaseProportionSimulations_underH0random[i] = random_improvement.mean()\n",
    "\n",
    "# The population parameter value under H0\n",
    "population_parameter_value_under_H0 = 0.5\n",
    "\n",
    "# Calculate the observed statistic\n",
    "observed_statistic = (patient_data.HealthScoreChange > 0).mean()\n",
    "simulated_statistics = IncreaseProportionSimulations_underH0random\n",
    "\n",
    "# Check which simulated statistics are greater than the observed statistic for a one-tailed test\n",
    "SimStats_more_extreme_than_ObsStat = simulated_statistics > observed_statistic\n",
    "\n",
    "# Calculate the one-tailed p-value\n",
    "one_tailed_p_value = np.mean(SimStats_more_extreme_than_ObsStat)\n",
    "\n",
    "# Output results\n",
    "print('Observed Statistic:', observed_statistic)\n",
    "print('One-Tailed P-Value:', one_tailed_p_value)\n",
    "\n",
    "# Summary of simulated statistics and comparison to observed statistic\n",
    "result_summary = pd.DataFrame({\n",
    "    '(Simulated) Statistic': simulated_statistics,\n",
    "    '> ' + str(observed_statistic) + ' ?': ['> ' + str(observed_statistic) + ' ?'] * number_of_simulations,\n",
    "    '\"as more extreme\"?': SimStats_more_extreme_than_ObsStat\n",
    "})\n",
    "\n",
    "# Display the result summary\n",
    "print(result_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adddcf9e",
   "metadata": {},
   "source": [
    "The changing reason are below:\n",
    "\n",
    "Directional Comparison for One-Tailed TestIn a two-tailed test:\n",
    "we check if the simulated statistics are \"as or more extreme\" than the observed statistic in both directions (greater than or less than). This is done by taking the absolute value of the differences.\n",
    "For a one-tailed test, we are only interested in one direction of the effect (e.g., whether the observed statistic is significantly greater than the null hypothesis). Therefore, the condition was changed to check if the simulated statistics are greater than the observed statistic.\n",
    "\n",
    "Calculating One-Tailed P-Value:\n",
    "\n",
    "Original Calculation:Not explicitly present in the original code because it was set up for a two-tailed test.\n",
    "However,now the one-tailed p-value is computed by taking the mean of the results from the one-tailed comparison. This gives the probability of observing a statistic as extreme as the observed statistic in the direction of the alternative hypothesis. This is different from the two-tailed p-value, which would involve considering both tails of the distribution.\n",
    "\n",
    "Output Adjustments:\n",
    "\n",
    "The code prints the observed statistic and the one-tailed p-value.\n",
    "The summary of simulated statistics reflects the one-tailed nature of the test.\n",
    "Reason:\n",
    "It is essential to communicate clearly what the hypothesis test evaluates (in this case, a one-tailed test for an increase in health score). This helps to clarify the test's focus and the corresponding p-value interpretation.\n",
    "\n",
    "Overall Interpretation Changes\n",
    "\n",
    "Null Hypothesis (H0):\n",
    "Remains the same: the vaccine has no average effect (mean health score change = 0).\n",
    "Alternative Hypothesis (H1):\n",
    "The one-tailed test specifically looks at whether the vaccine has a positive average effect (mean health score change > 0). This focus alters the interpretation, as we are now interested only in evidence that supports an increase rather than any significant change, which is what a two-tailed test evaluates.\n",
    "\n",
    "Expected P-value Differences:\n",
    "One-Tailed vs. Two-Tailed P-value:\n",
    "A one-tailed p-value is expected to be smaller than the two-tailed p-value when the observed effect is in the direction of the alternative hypothesis (e.g., a positive health score change).\n",
    "This is because the one-tailed test concentrates the significance level on one side of the distribution, whereas the two-tailed test allocates significance across both tails. Thus, the p-value for a one-tailed test represents a more focused test of the hypothesis.\n",
    "\n",
    "Summary of Key Changes:\n",
    "Condition Changes: Adjusted to only consider the relevant tail of the distribution.\n",
    "P-value Calculation: Shifted from two-tailed to one-tailed, focusing on the direction of interest.\n",
    "Output Clarification: Clearly distinguishes between one-tailed and two-tailed tests to ensure accurate interpretation.\n",
    "\n",
    "https://chatgpt.com/share/670f2913-d0fc-8007-af8b-2f07802d9299"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62b6393",
   "metadata": {},
   "source": [
    "Q8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8d0531",
   "metadata": {},
   "source": [
    "Problem Introduction: this experiment aims to determine whether STA130 students can accurately identify the order in which milk and tea are poured into a cup. This echoes Ronald Fisher's original experiment with Dr. Muriel Bristol, who claimed she could taste a difference based on the pouring order.\n",
    "\n",
    "Relationship to the Original Experiment: while Fisher’s study involved just two participants, our experiment includes a larger sample of 80 STA130 students. Additionally, Fisher focused on personal taste preference, while our study assesses the students' ability to accurately identify the pouring order.\n",
    "\n",
    "Hypotheses:\n",
    "\n",
    "Null Hypothesis: Students’ success in identifying the pouring order is due to random guessing.\n",
    "\n",
    "Alternative Hypothesis: Students can distinguish the pouring order better than chance.\n",
    "\n",
    "Quantitative Analysis are in next chart.\n",
    "\n",
    "Findings and Discussion: based on the calculations, we obtained a z-test statistic of approximately 2.00 and a p-value of approximately 0.0456. Since this p-value is less than the common alpha level of 0.05, we reject the null hypothesis.\n",
    "\n",
    "This result suggests that STA130 students have the ability to correctly identify the order of milk and tea being poured at a rate significantly higher than what would be expected by chance.\n",
    "\n",
    "Conclusion regarding the Null Hypothesis: in conclusion, the statistical analysis indicates that the STA130 students are able to distinguish the order in which milk and tea are poured. The p-value obtained from the hypothesis test provides sufficient evidence to reject the null hypothesis, suggesting that the students' performance is not due to random guessing.\n",
    "\n",
    "Further studies could involve larger sample sizes or variations in the tea and milk types to explore if the results hold across different contexts or demographics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ead91",
   "metadata": {},
   "source": [
    "Methodology code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16268a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Setting the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n = 80  # Sample size\n",
    "X = 49  # Number of correct responses\n",
    "p_null = 0.5  # Null hypothesis proportion\n",
    "\n",
    "# Sample proportion\n",
    "hat_p = X / n\n",
    "\n",
    "# Standard Error under null hypothesis\n",
    "SE = np.sqrt(p_null * (1 - p_null) / n)\n",
    "\n",
    "# Z-test statistic\n",
    "z = (hat_p - p_null) / SE\n",
    "\n",
    "# Two-tailed p-value\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "\n",
    "# Output the results\n",
    "hat_p, SE, z, p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9725790",
   "metadata": {},
   "source": [
    "Explanation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc94f7d",
   "metadata": {},
   "source": [
    "Imports: The code begins by importing the necessary libraries:\n",
    "numpy (imported as np) is used for numerical operations.\n",
    "scipy.stats (imported as stats) provides functions for statistical tests and distributions.\n",
    "\n",
    "Random Seed: This line sets a seed for the random number generator. By setting the seed to a specific value (42 in this case), we ensure that the results are reproducible; every time the code runs, it produces the same random numbers.\n",
    "\n",
    "Random Seed: This line sets a seed for the random number generator. By setting the seed to a specific value (42 in this case), we ensure that the results are reproducible; every time the code runs, it produces the same random numbers.\n",
    "\n",
    "Sample Proportion Calculation: This line calculates the sample proportion of correct responses.\n",
    "\n",
    "Standard Error Calculation: This line calculates the standard error (SE) of the sample proportion assuming the null hypothesis is true. The standard error measures how much variability we expect in the sample proportion if we were to repeatedly take samples of size n under the null hypothesis.\n",
    "\n",
    "Z-Test Statistic Calculation: This line computes the z-test statistic which measures how many standard errors the sample proportion is away from the null hypothesis proportion. A larger absolute value indicates a more significant deviation from what we would expect under the null hypothesis.\n",
    "\n",
    "P-Value Calculation: This line calculates the two-tailed p-value:\n",
    "stats.norm.cdf(abs(z)) computes the cumulative distribution function (CDF) value for the calculated z-score, which gives the probability that a value from a standard normal distribution is less than z.\n",
    "We calculate the probability of obtaining a result as extreme as the z-score in both directions (hence the multiplication by 2), reflecting the two-tailed nature of the test.\n",
    "\n",
    "Results Output: This line outputs the calculated values for the sample proportion, standard error (SE), z-test statistic (z), and the p-value. These results can then be used to interpret the statistical significance of the findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e61c9f7",
   "metadata": {},
   "source": [
    "Visualization support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08864eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate values for normal distribution\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = stats.norm.pdf(x, loc=p_null, scale=SE)\n",
    "\n",
    "# Create histogram of the sample proportion\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, label='Normal Distribution', color='blue')\n",
    "plt.axvline(x=hat_p, color='red', linestyle='--', label='Sample Proportion')\n",
    "plt.title('Sampling Distribution of the Sample Proportion')\n",
    "plt.xlabel('Proportion')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1dcf2",
   "metadata": {},
   "source": [
    "Q9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1cfc5",
   "metadata": {},
   "source": [
    "Yes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
