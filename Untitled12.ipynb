{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02fed4b5",
   "metadata": {},
   "source": [
    "Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef0334",
   "metadata": {},
   "source": [
    "The main difference between Simple Linear Regression and Multiple Linear Regression lies in the number of independent (predictor) variables used to predict the dependent (response) variable.\n",
    "\n",
    "In regard to Simple Linear Regression, SLR uses one independent variable to predict the value of a dependent variable.\n",
    "It fits a linear relationship of the form Y = Œ≤0 + Œ≤1*X + œµ , where ùëå is the dependent variable, ùëã is the independent variable, Œ≤0 is the intercept,Œ≤1 is the slope of the line, and œµ is the error term.\n",
    "\n",
    "Concerning Multiple Linear Regression, MLR uses two or more independent variables to predict the dependent variable.\n",
    "It fits a linear relationship of the form Y=Œ≤0 + Œ≤1*X1 + Œ≤2*X2+...+Œ≤n*Xn + œµ, where ùëã1,ùëã2,...,ùëãùëõ are the multiple independent variables, and ùõΩ1,ùõΩ2,...,ùõΩùëõ are their respective coefficients.\n",
    "\n",
    "When it come to the benefits of multiple linear regression over simple linear regression, it can increase Predictive Power, better understand  relationships, control for confounding variables and handle complex data.\n",
    "\n",
    "Firstly, MLR can incorporate multiple variables, which allows it to capture more information that may influence the dependent variable. This often results in better accuracy and predictive power because it can account for the effects of more factors.\n",
    "\n",
    "\n",
    "Besides, MLR allows you to see how different variables affect the outcome simultaneously, making it possible to understand the partial effects of each predictor variable while holding others constant.\n",
    "\n",
    "\n",
    "In additon, by including multiple variables, MLR helps isolate the effect of each predictor variable, reducing the risk that omitted variables might bias the results.\n",
    "\n",
    "\n",
    "Moreover, MLR is more suitable for real-world data, where multiple factors often jointly influence outcomes. It enables more nuanced insights, particularly in cases where interactions between variables are important.\n",
    "\n",
    "However, MLR also requires more data and careful selection of variables, as adding too many predictors without careful analysis can lead to overfitting and a loss of model interpretability.\n",
    "\n",
    "https://chatgpt.com/share/673402d0-cbb0-8009-b0ee-e1a81cba4dbb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a99a9",
   "metadata": {},
   "source": [
    "Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824523ba",
   "metadata": {},
   "source": [
    "Identifying the Outcome and Predictor Variables\n",
    "Outcome Variable: The primary variable we're interested in predicting is likely the sales or revenue generated from sports equipment sales. This is a continuous variable that represents the effectiveness of the advertising campaigns in monetary terms.\n",
    "\n",
    "1.Predictor Variables:\n",
    "\n",
    "TV Advertising Budget (TV_Ad): This is the amount of money the company spends on TV ads. It‚Äôs a continuous variable.\n",
    "Online Advertising Budget (Online_Ad): This is the amount spent on online ads. Like the TV budget, it‚Äôs also a continuous variable.\n",
    "\n",
    "2.Interaction EffectÔºö\n",
    "The scenario suggests that the effectiveness of the TV ad might depend on the amount spent on online advertising and vice versa. This means that there could be an interaction effect between TV and online advertising. If the interaction is meaningful, we would include a term in our model that represents the combined effect of both advertising budgets.\n",
    "\n",
    "For example, spending a lot on both types of advertising may have a more substantial effect than just the sum of each individually, or it could be that spending more in one medium makes the other less effective.\n",
    "\n",
    "3.Linear ModelsÔºö\n",
    "To predict sales with and without the interaction, we can create two linear models:\n",
    "\n",
    "Model without Interaction:\n",
    "\n",
    "Without an interaction, the model would simply be a linear combination of both advertising budgetsÔºöSales=Œ≤0 + Œ≤1√óTV_Ad + Œ≤2√óOnline_Ad + œµÔºåwhere: ùõΩ0 is the intercept (baseline sales when both advertising budgets are zero). ùõΩ1 represents the effect of TV advertising on sales. ùõΩ2 represents the effect of online advertising on sales. œµ is the error term, capturing random variation in sales.\n",
    "\n",
    "Model with Interaction:\n",
    "\n",
    "With an interaction, we add an extra term that represents the interaction between TV and online advertising:\n",
    "Sales=Œ≤0 + Œ≤1√óTV_Ad + Œ≤2√óOnline_Ad + Œ≤3√ó(TV_Ad√óOnline_Ad)+œµÔºåwhere: ùõΩ3 represents the effect of the interaction between TV and online advertising on sales.\n",
    "\n",
    "4. Making Predictions with These ModelsÔºö\n",
    "Without Interaction: To make predictions, you would input the amounts for TV and online advertising into the formula without an interaction term. This model assumes that the effect of each advertising medium on sales is independent of the other, so increasing one medium's budget doesn‚Äôt affect the effectiveness of the other.\n",
    "\n",
    "With Interaction: In the model with the interaction, the prediction depends on the combined effect of both advertising budgets. This model implies that the effectiveness of one medium is influenced by the budget spent on the other. For example, if ùõΩ3 is positive, then high spending on both TV and online ads will yield a greater-than-expected increase in sales.\n",
    "\n",
    "5. Predictions with Binary \"High\" or \"Low\" CategoriesÔºö\n",
    "If we switch from continuous advertising budgets to binary categories (\"high\" or \"low\"), the models would adjust to reflect these as categorical variables instead:\n",
    "Let:\n",
    "TV_Ad_High = 1 if TV ad budget is high, 0 if low.\n",
    "Online_Ad_High = 1 if online ad budget is high, 0 if low.\n",
    "Model without Interaction (Binary Predictors): \n",
    "Sales=Œ≤0 + Œ≤1√óTV_Ad_High + Œ≤2√óOnline_Ad_High + œµ\n",
    "Model with Interaction (Binary Predictors):\n",
    "Sales=Œ≤0 + Œ≤1√óTV_Ad_High + Œ≤2√óOnline_Ad_High + Œ≤3√ó(TV_Ad_High√óOnline_Ad_High) + œµ\n",
    "\n",
    "In these binary models:\n",
    "Without Interaction: The effect of having a high TV or high online budget is additive and does not depend on the other budget being high or low.\n",
    "With Interaction: If both budgets are high, the interaction term (ùõΩ3) would be active, indicating a joint effect when both advertising types are set to high. This would modify the predicted sales outcome based on this combined \"high-high\" scenario.\n",
    "\n",
    "In summary, in terms of model without interaction, predicts the outcome by assuming each predictor has an independent impact. For example, spending more on TV ads has a predictable effect on sales, regardless of the online budget.\n",
    "\n",
    "Regarding model with interaction, adds a combined effect of the two predictors, allowing the relationship to account for situations where the impact of one budget depends on the level of the other.\n",
    "\n",
    "https://chatgpt.com/share/6734066e-dfc8-8009-85ab-229bce4119ae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98bb4d",
   "metadata": {},
   "source": [
    "Q3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9243d9",
   "metadata": {},
   "source": [
    "The first step is to prepare data and outcome variable. Load the data and, if necessary, convert a categorical outcome variable into a binary format (0 or 1). Choose several continuous, binary, or categorical predictor variables.\n",
    "The second step is model specification. Specify the logistic regression model formula. For logistic regression, use statsmodels.formula.api.logit to fit a logistic model to your binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# Load example data; replace with Canadian Social Connection Survey data\n",
    "# For this example, we're using Pokemon data as a placeholder\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Example transformation for a binary outcome (e.g., whether a Pokemon is of type 'Fire')\n",
    "data['is_fire_type'] = (data['Type 1'] == 'Fire').astype(int)\n",
    "\n",
    "# Model Specification: Using an additive model with interaction terms as example\n",
    "formula = 'is_fire_type ~ Attack + Legendary + Attack:Legendary + Defense + C(Generation)'\n",
    "\n",
    "# Fit logistic regression model\n",
    "model = smf.logit(formula, data=data).fit()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d8b6c",
   "metadata": {},
   "source": [
    "Interpretation of Model Output:\n",
    "\n",
    "In model.summary(), we will find:\n",
    "\n",
    "Coefficients: These represent the log-odds effect of each predictor on the binary outcome.\n",
    "\n",
    "P-values: Indicates if predictors are statistically significant.\n",
    "Odds Ratios: You can exponentiate coefficients to interpret them as the impact on the odds of the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517abea1",
   "metadata": {},
   "source": [
    "Visualizing the Data and \"Best Fit Lines\":\n",
    "\n",
    "Since logistic regression does not directly yield a linear relationship, we can plot the binary predictor or categories on the x-axis. Then display a smoothed logistic curve (pretend it‚Äôs a linear relationship). Also add some noise to continuous predictors and plot points to show spread.\n",
    "\n",
    "Here‚Äôs how to approximate it in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ebf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Sample data for continuous + binary predictors\n",
    "np.random.seed(0)\n",
    "x_continuous = np.linspace(data['Attack'].min(), data['Attack'].max(), 100)\n",
    "x_binary = np.random.choice([0, 1], 100)\n",
    "\n",
    "# Add noise\n",
    "y_values = model.predict(pd.DataFrame({\n",
    "    'Attack': x_continuous,\n",
    "    'Legendary': x_binary\n",
    "}))\n",
    "\n",
    "# Additive Specification Plot\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_continuous, y=y_values, mode='lines', name='Best Fit Line (Additive)'))\n",
    "fig.add_trace(go.Scatter(x=x_continuous, y=y_values + np.random.normal(scale=0.05, size=100),\n",
    "                         mode='markers', name='Noisy Data'))\n",
    "fig.update_layout(title=\"Logistic Regression (Additive Model Approximation)\",\n",
    "                  xaxis_title=\"Attack\", yaxis_title=\"Predicted Probability (is_fire_type)\")\n",
    "fig.show()\n",
    "\n",
    "# Synergistic Specification Plot (adding interaction effect)\n",
    "y_values_interaction = model.predict(pd.DataFrame({\n",
    "    'Attack': x_continuous,\n",
    "    'Legendary': x_binary,\n",
    "    'Attack:Legendary': x_continuous * x_binary  # Simulating interaction term\n",
    "}))\n",
    "\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Scatter(x=x_continuous, y=y_values_interaction, mode='lines', name='Best Fit Line (Interaction)'))\n",
    "fig2.add_trace(go.Scatter(x=x_continuous, y=y_values_interaction + np.random.normal(scale=0.05, size=100),\n",
    "                          mode='markers', name='Noisy Data'))\n",
    "fig2.update_layout(title=\"Logistic Regression (Interaction Model Approximation)\",\n",
    "                   xaxis_title=\"Attack\", yaxis_title=\"Predicted Probability (is_fire_type)\")\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941486b9",
   "metadata": {},
   "source": [
    "Interpreting the Visualizations:\n",
    "\n",
    "Additive Model: Shows the impact of individual predictors on the outcome. If the line captures the data points well, the model without interactions might be sufficient.\n",
    "\n",
    "Interaction Model: Here, the \"best fit\" line adjusts based on the interaction term, revealing any combined effect of predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff1b6c",
   "metadata": {},
   "source": [
    "Q4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956448aa",
   "metadata": {},
   "source": [
    "The apparent contradiction arises from the difference between individual predictor significance and overall model fit.\n",
    "\n",
    "The statement \"the model only explains 17.6% of the variability in the data\" refers to the model's ùëÖ**2 value. ùëÖ**2 is a measure of the proportion of the variance in the dependent variable (here, HP) that is explained by the independent variables (here, Sp. Def, Generation, and their interaction).\n",
    "\n",
    "A low ùëÖ**2 (17.6%) means that only a small portion of HP's variability is accounted for by this model. This suggests that other factors not included in the model likely play a larger role in predicting HP.\n",
    "\n",
    "Even with a low ùëÖ**2, individual predictors can still be statistically significant if they consistently influence HP. This significance is shown by p-values below a threshold (often 0.05), indicating strong evidence against the null hypothesis of \"no effect.\"\n",
    "\n",
    "Large coefficients (above 10) further suggest that certain predictors have a substantial impact on HP when they do influence it.\n",
    "\n",
    "The model captures some effects of Sp. Def and Generation, but they explain only a fraction of the variability in HP. Thus, while the predictors significantly affect HP, their influence alone does not provide a complete explanation, and other variables likely contribute to HP's variability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc3a29",
   "metadata": {},
   "source": [
    "Q5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ad7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0] * 0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column) with \"None\"\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dd49b5",
   "metadata": {},
   "source": [
    "This section handles missing data in the pokeaman dataset by filling NaN values in the \"Type 2\" column with 'None'.\n",
    "Then, it splits the dataset into a training set (pokeaman_train) and a test set (pokeaman_test). The training set is 50% of the original dataset (fifty_fifty_split_size).\n",
    "The purpose of the code is to prepares the data for modeling by handling missing values and splitting into training and testing sets to ensure an unbiased evaluation of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb891537",
   "metadata": {},
   "source": [
    "Here, a linear regression model is specified, predicting HP based on Attack and Defense.\n",
    "This model is fitted on the training data (pokeaman_train), and the model's summary statistics are printed.\n",
    "The purpose of the code to train a basic linear regression model to predict HP based on two predictors (Attack and Defense). The summary provides insights into coefficients, p-values, and overall model fit metrics (like R-squared)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a61176",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model3)[0, 1]**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ef2b56",
   "metadata": {},
   "source": [
    "This cell calculates predictions (yhat_model3) for HP on the test set (pokeaman_test) using the previously fitted model.\n",
    "It then compares the \"in-sample\" R-squared (training data) with the \"out-of-sample\" R-squared (test data) using the correlation between the true and predicted HP values.\n",
    "Purpose: Evaluate model performance by checking R-squared on both the training set (in-sample) and the test set (out-of-sample). This shows how well the model generalizes to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2110734",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c788657",
   "metadata": {},
   "source": [
    "Complex Model with Interactions:\n",
    "\n",
    "This model (model_spec4) is a more complex version of the first model, incorporating interactions between various predictors (Attack, Defense, Speed, Legendary, Sp. Def, Sp. Atk).\n",
    "The interaction terms, denoted by *, suggest that the relationship between HP and any of these features is not just linear but also involves combinations of these features (e.g., Attack * Defense).\n",
    "Note: The commented-out code warns against adding too many interaction terms, which would lead to a combinatorially large number of interactions, likely overwhelming the system‚Äôs capacity to compute them.\n",
    "\n",
    "Model Fitting and Evaluation:\n",
    "\n",
    "The formula is used to create a more complex linear regression model, which is fitted to the training data.\n",
    "The summary of this more complex model is displayed, providing insights into the relationship between HP and the various predictors.\n",
    "Like the simpler model, predictions are made on the test data, and both in-sample and out-of-sample R-squared values are printed.\n",
    "Purpose: This section shows the effect of using a more complex model with interaction terms. It demonstrates the trade-off between model complexity (more predictors and interactions) and the potential to capture more nuanced relationships, but also the risk of overfitting or making the model computationally infeasible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb865fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model4)[0, 1]**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de1cce1",
   "metadata": {},
   "source": [
    "This cell generates predictions for HP on the test set (pokeaman_test) using the complex model (model4_fit).\n",
    "It compares in-sample and out-of-sample R-squared values, similar to Cell 3.\n",
    "The purposeof the code is to assess the performance of the complex model by comparing in-sample and out-of-sample R-squared. Comparing these values with Model 3‚Äôs scores provides insight into whether adding complexity improves generalization.\n",
    "\n",
    "https://chatgpt.com/share/67341cfa-daf0-8007-a7ba-9ea3d9284306"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bf5da9",
   "metadata": {},
   "source": [
    "Q6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa9853d",
   "metadata": {},
   "source": [
    "1. Creating Predictors in the Design Matrix (model4_spec.exog):\n",
    "The formula model4_linear_form in Model 4 includes interactions among Attack, Defense, Speed, Legendary, Sp. Def, and Sp. Atk.\n",
    "The interaction terms (* in the formula) expand the predictors significantly, adding combinations like Attack*Defense, Attack*Defense*Speed, etc., creating a high-dimensional design matrix.\n",
    "This matrix, model4_spec.exog, is the set of predictors (in matrix form) used to predict the outcome variable HP, stored in model4_spec.endog.\n",
    "2. Impact of Multicollinearity on Out-of-Sample Generalization:\n",
    "Multicollinearity occurs when some predictors in model4_spec.exog are highly correlated, often due to complex interactions among similar variables (e.g., different interactions involving Attack and Defense).\n",
    "When there‚Äôs high multicollinearity, small changes in the test data can lead to large, unstable shifts in model predictions.\n",
    "This instability reduces the model‚Äôs out-of-sample generalization, as seen by the reduced out-of-sample R-squared for model4_fit. The \"Condition Number\" (Cond. No.) in the model summary indicates the degree of multicollinearity‚Äîvalues in the trillions suggest extreme multicollinearity, leading to poor generalization.\n",
    "3. Attempted Solution with Centering and Scaling:\n",
    "Centering and scaling (standardizing) predictors can sometimes reduce multicollinearity. In the revised model (model4_CS_spec), predictors are standardized (except for Legendary, an indicator variable).\n",
    "However, even after standardization, model4_CS_fit still has an extremely high condition number, meaning multicollinearity persists, likely due to the interactions among already-correlated variables.\n",
    "\n",
    "Summary\n",
    "The model4_linear_form specification creates a large set of interaction predictors in the design matrix, which leads to high multicollinearity. This multicollinearity causes prediction instability, harming out-of-sample generalization and producing a high \"Condition Number.\" Centering and scaling improve multicollinearity slightly but are insufficient for a model with many interaction terms among correlated variables.\n",
    "\n",
    "https://chatgpt.com/share/67341cfa-daf0-8007-a7ba-9ea3d9284306"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd7a48c",
   "metadata": {},
   "source": [
    "Q7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a48361",
   "metadata": {},
   "source": [
    "The rationale for progressing from model5_linear_form to model6_linear_form and model7_linear_form lies in iteratively refining the model by selecting and transforming predictors to improve predictive accuracy and interpretability.\n",
    "\n",
    "Model 5 starts with a broad set of predictors, including main numeric predictors (Attack, Defense, Speed, Special Defense, Special Attack) and categorical variables (Generation, Type 1, Type 2). This model provides a comprehensive baseline using all these features to capture general trends in the data.\n",
    "Model 6 refines Model 5 by focusing on only the significant predictors. Less relevant predictors are removed (like Defense), while specific indicators (e.g., Type 1 being \"Normal\" or \"Water,\" and Generations 2 and 5) are added based on Model 5‚Äôs results. This improves interpretability by keeping only impactful variables.\n",
    "Model 7 further builds on Model 6 by adding interaction terms among numeric predictors, aiming to capture complex relationships between variables. This model also uses centering and scaling in a modified version (model7_linear_form_CS) to address issues with multicollinearity, leading to a much lower condition number (from over 2 billion to 15.4). This scaling makes the model more stable by reducing the variance inflation effect in the estimation.\n",
    "In summary, each model stage removes insignificant predictors, refines relevant terms, and adds interactions as needed, making the model more focused, interpretable, and robust.\n",
    "\n",
    "https://chatgpt.com/share/673421dd-0dac-8007-82a5-e2bf1803b89d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27847e",
   "metadata": {},
   "source": [
    "Q8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378c044",
   "metadata": {},
   "source": [
    "Code\n",
    "Simulate data and initialize metrics: Start by simulating some sample data or splitting a dataset. Define arrays to store the \"in-sample\" and \"out-of-sample\" metrics.\n",
    "\n",
    "Loop through multiple iterations: For each iteration, train the model on the \"in-sample\" (training) data and test it on the \"out-of-sample\" (test) data. Collect the performance metrics.\n",
    "\n",
    "Plot the results: After collecting metrics from all iterations, plot them to visualize the distribution of \"in-sample\" and \"out-of-sample\" performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c223846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Placeholder lists to store the performance metrics\n",
    "in_sample_scores = []\n",
    "out_sample_scores = []\n",
    "\n",
    "# Generate synthetic data\n",
    "X = np.random.rand(100, 1)  # 100 samples, 1 feature\n",
    "y = 3 * X.squeeze() + np.random.randn(100) * 0.5  # Linear relationship with some noise\n",
    "\n",
    "# Run multiple iterations\n",
    "n_iterations = 50\n",
    "for _ in range(n_iterations):\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Initialize and train model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate in-sample and out-of-sample errors\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    in_sample_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    out_sample_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    # Append the metrics to the lists\n",
    "    in_sample_scores.append(in_sample_mse)\n",
    "    out_sample_scores.append(out_sample_mse)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(in_sample_scores, label='In-sample MSE', color='blue')\n",
    "plt.plot(out_sample_scores, label='Out-of-sample MSE', color='orange')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.title(\"In-Sample vs Out-of-Sample Model Performance Across Iterations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56a2d9f",
   "metadata": {},
   "source": [
    "1.In-Sample Performance: The \"in-sample\" performance measures how well the model fits the training data. These metrics are typically better because the model is optimized for this data. If you see consistently lower errors for \"in-sample\" than \"out-of-sample\" data, it reflects that the model is fitting the training data well.\n",
    "\n",
    "2.Out-of-Sample Performance: The \"out-of-sample\" performance measures how well the model generalizes to new, unseen data (here, the test set). The variability in \"out-of-sample\" metrics highlights how model performance might fluctuate in real-world applications.\n",
    "\n",
    "3.Demonstration Purpose: By observing these fluctuations across iterations without setting a random seed, we see the variability in model evaluation due to different train-test splits. This approach provides insights into model stability and reliability. Ideally, \"in-sample\" and \"out-of-sample\" errors should be close if the model generalizes well.\n",
    "\n",
    "https://chatgpt.com/share/673422c7-8ae0-8007-93b4-3d2828c3bf83"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59680e73",
   "metadata": {},
   "source": [
    "Q9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6028c1",
   "metadata": {},
   "source": [
    "The provided code appears to involve building and evaluating multiple regression models on a dataset (likely related to Pok√©mon) to predict the HP (Hit Points) of Pok√©mon based on certain features, using the ordinary least squares (OLS) method. The dataset contains Pok√©mon grouped by generation, and the models attempt to make predictions using different subsets of the data. The main metric of interest here is R-squared (R¬≤), which measures how well the model explains the variance in the data.\n",
    "\n",
    "1. Model 7 for Generation 1 (gen1):\n",
    "\n",
    " ‚Ä¢ Step 1: A regression model (model7_gen1_predict_future) is created using data for Generation 1 Pok√©mon.\n",
    " ‚Ä¢ Step 2: The model is fitted, and its in-sample R-squared is printed, indicating how well the model fits the training data.\n",
    " ‚Ä¢ Step 3: The out-of-sample R-squared is computed using predictions on a test set (pokeaman_test) and comparing it to actual HP values.\n",
    " ‚Ä¢ Step 4: A second prediction is made for Pok√©mon that are not from Generation 1. This checks how well the model generalizes to other generations.\n",
    "\n",
    "2. Model 7 for Generations 1-5 (gen1to5):\n",
    "\n",
    " ‚Ä¢ Step 1: A regression model (model7_gen1to5_predict_future) is created using data from Generations 1 to 5, excluding Generation 6.\n",
    " ‚Ä¢ Step 2: The model is fitted and its in-sample R-squared is printed.\n",
    " ‚Ä¢ Step 3: Similar to step 3 of part 1, the out-of-sample R-squared is computed, but now using data from Generation 6.\n",
    " ‚Ä¢ Step 4: This checks how well a model trained on earlier generations predicts HP for Generation 6.\n",
    "\n",
    "3. Model 6 for Generation 1 (gen1):\n",
    "\n",
    " ‚Ä¢ Step 1: A regression model (model6_gen1_predict_future) is created for Generation 1, but now using a different model structure (model6_linear_form).\n",
    " ‚Ä¢ Step 2: The same process as before is repeated, computing both in-sample and out-of-sample R-squared for the model.\n",
    "\n",
    "4. Model 6 for Generations 1-5 (gen1to5):\n",
    "\n",
    " ‚Ä¢ Step 1: A regression model (model6_gen1to5_predict_future) is created for Generations 1-5, excluding Generation 6.\n",
    " ‚Ä¢ Step 2: The process is repeated to compute both in-sample and out-of-sample R-squared for this model.\n",
    "\n",
    "Key Insights:\n",
    "\n",
    " ‚Ä¢ In-Sample R-squared: Measures the fit of the model on the data it was trained on. A higher value means the model does a good job explaining the variability in the training data.\n",
    " ‚Ä¢ Out-of-Sample R-squared: Measures how well the model generalizes to unseen data. It‚Äôs computed by comparing the predicted values to actual values in a test set. A higher value means the model generalizes well.\n",
    "\n",
    "Important Observations:\n",
    "\n",
    " ‚Ä¢ Comparing the in-sample R-squared between different models gives an idea of how well each model performs on the data it was trained on.\n",
    " ‚Ä¢ Comparing the out-of-sample R-squared provides insight into how well the model generalizes to data from generations that were not part of the training set. A model trained on earlier generations (gen1, gen1-5) may perform poorly when predicting HP for Generation 6 (out-of-sample), as the Pok√©mon in Generation 6 could differ significantly in their HP values.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "This analysis helps determine how well different models trained on different generations of Pok√©mon can predict the HP for Pok√©mon from unseen generations. Comparing the in-sample and out-of-sample performance (R-squared) shows whether a model is simply overfitting to the training data or if it generalizes well to new, unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
